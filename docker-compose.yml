version: "3.8"
services:  
  crawler_elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.1
    ports:
      - 9200:9200
      - 9300:9300
    container_name: es_container
    environment:
      - discovery.type=single-node
    volumes:
      - es-data:/usr/share/elasticsearch/data
      - ./Services/Elasticsearch/stoplist.txt:/usr/share/elasticsearch/config/my_stoplist.txt
      - ./Services/Elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    networks:
      - crawlernet  
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 1s
      timeout: 3s
      retries: 60
  crawler_redis:
    image: redis
    container_name: redis_container
    ports:
      - 6379:6379
    networks:
      - crawlernet
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 30
  crawler_job:
    build: .
    command: python ./MainCrawler.py
    container_name: crawler_container
    environment:
      - CRAWLER_VERSION:V1
    depends_on: 
      crawler_elasticsearch:
        condition: service_healthy
      crawler_redis:
        condition: service_healthy
    networks:
      - crawlernet
networks: 
  crawlernet:
    driver: bridge

volumes:
  es-data: #left empty as default arguments work fine